# Deal Radar â€“ M&A Intelligence Platform

Eine KI-gestÃ¼tzte Plattform zur Analyse von GeschÃ¤ftsberichten und Identifikation von M&A-Opportunities basierend auf Distressed-Signalen.

## Features

- ğŸ” **Intelligente Signalanalyse**: Erkennung von Carve-outs, Financial Distress und Business Services Opportunities
- ğŸ¤– **AI-Chat**: OpenAI gpt-4o-mini fÃ¼r kontextuelle Analysen
- ğŸ“š **ChromaDB Vector Search**: Effiziente Suche Ã¼ber 13.000+ Chunks
- ğŸ“„ **PDF-Integration**: Automatische Extraktion und Indizierung von GeschÃ¤ftsberichten
- ğŸŒ **Web-UI**: Interaktive OberflÃ¤che zum Erkunden von Unternehmen und Signalen

## Technologie

- **Backend**: Python 3 mit FastHTTP Server
- **Vector Database**: ChromaDB mit OpenAI Embeddings
- **Frontend**: Vanilla JavaScript mit responsivem Design
- **AI**: OpenAI API (gpt-4o-mini)

## Lokale Installation

```bash
# Repository klonen
git clone https://github.com/yourusername/deal-radar.git
cd deal-radar

# Python Dependencies installieren
pip install -r deal_radar/requirements.txt

# Server starten
cd deal_radar/webapp
python3 server.py 8000
```

Die Webapp lÃ¤uft dann unter: **http://localhost:8000**

## Deployment auf Netlify

Diese Webapp ist optimiert fÃ¼r Netlify Deployment:

1. **GitHub verbinden**: Repo mit Netlify verknÃ¼pfen
2. **Build Command**: `echo "No build required"`
3. **Publish Directory**: `deal_radar/webapp`
4. **Environment Variables**:
   - `OPENAI_API_KEY`: Your OpenAI API key
   - Weitere sind optional

Die Python-Backend wird lokal ausgefÃ¼hrt, die Frontend-Assets (HTML, CSS, JS) werden Ã¼ber Netlify serviert.

## Umgebungsvariablen

Erstelle eine `.env` Datei im `deal_radar/` Verzeichnis:

```
OPENAI_API_KEY=sk-...
```

## Projektstruktur

```
deal_radar/
â”œâ”€â”€ webapp/              # Web-UI (Frontend + Backend Server)
â”‚   â”œâ”€â”€ server.py        # Python HTTP Server
â”‚   â”œâ”€â”€ index.html       # Main UI
â”‚   â”œâ”€â”€ app.js           # Frontend Logic
â”‚   â”œâ”€â”€ styles.css       # Styling
â”‚   â””â”€â”€ pipeline_queue.py
â”œâ”€â”€ src/                 # Pipeline Scripts
â”‚   â”œâ”€â”€ 01_discover_ir.py
â”‚   â”œâ”€â”€ 02_collect_pdf_links.py
â”‚   â”œâ”€â”€ 03_download_pdfs.py
â”‚   â”œâ”€â”€ 04_extract_text.py
â”‚   â”œâ”€â”€ 05_scan_reports.py
â”‚   â”œâ”€â”€ 06_score_and_export.py
â”‚   â”œâ”€â”€ 07_build_index.py
â”‚   â””â”€â”€ 08_chat.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chroma_db/       # Vector Database
â”‚   â”œâ”€â”€ downloads/       # PDF Files
â”‚   â”œâ”€â”€ extracted_text/  # Extracted Text
â”‚   â””â”€â”€ outputs/         # Results (CSV, JSONL)
â””â”€â”€ requirements.txt
```

## API Endpoints

- `GET /api/companies` â€“ Liste aller Unternehmen
- `GET /api/stats` â€“ Ãœbersichtsstatistiken
- `GET /api/report?company=<id>` â€“ Analyse fÃ¼r ein Unternehmen
- `POST /api/chat` â€“ AI Chat

## Author

Tobi

## License

MIT
